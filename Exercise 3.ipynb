{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "task description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ner/gmb.csv\",encoding = 'latin1')\n",
    "data = data.fillna(method = 'ffill')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Get_sentence(object):\n",
    "    def __init__(self,data):\n",
    "        self.n_sent=1\n",
    "        self.data = data\n",
    "        agg_func = lambda s:[(w,p,t) for w,p,t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                     s[\"POS\"].values.tolist(),\n",
    "                                                     s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = Get_sentence(data)\n",
    "sentence = getter.sentences\n",
    "sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "\n",
    "words_tag = list(set(data[\"Tag\"].values))\n",
    "\n",
    "word_idx = {w : i+1 for i ,w in enumerate(words)}\n",
    "tag_idx =  {t : i for i ,t in enumerate(words_tag)}\n",
    "\n",
    "num_words = len(words)\n",
    "num_words_tag = len(words_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "max_len = 50\n",
    "X = [[word_idx[w[0]] for w in s] for s in sentence]\n",
    "X = pad_sequences(maxlen = max_len,sequences = X,padding = 'post',value = num_words-1)\n",
    "y = [[tag_idx[w[2]] for w in s] for s in sentence]\n",
    "y = pad_sequences(maxlen = max_len,sequences = y,padding = 'post',value = tag_idx['O'])\n",
    "y = [to_categorical(i,num_classes = num_words_tag) for i in  y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.layers import LSTM,Embedding,Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D,Bidirectional\n",
    "from tensorflow.python.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Input(shape = (max_len,)))\n",
    "model.add(Embedding(input_dim = num_words,output_dim = max_len,input_length = max_len))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(Bidirectional(LSTM(units=100,return_sequences = True, recurrent_dropout = 0.1)))\n",
    "model.add(TimeDistributed(Dense(num_words_tag,activation = 'softmax')))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "# from livelossplot import PlotLossesKeras\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy',patience =2,verbose = 0,mode = 'max',restore_best_weights = False)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,np.array(y_train),\n",
    "    validation_split =0.2,\n",
    "    batch_size = 64,\n",
    "    epochs = 3,\n",
    "    verbose =1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "Y_test = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl https://nilsreiter.de/challenge.wb.csv > data/ner/challenge.wb.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = pd.read_csv(\"data/ner/challenge.wb.csv\", header = 0, names=[\"Sentence #\",\"Word\",\"POS\",\"Tag\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = Get_sentence(challenge)\n",
    "sentence = getter.sentences\n",
    "sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "x_challenge = [[word_idx.get(w[0],0) for w in s] for s in sentence]\n",
    "x_challenge = pad_sequences(maxlen = max_len,sequences = x_challenge,padding = 'post',value = num_words-1)\n",
    "y_challenge = [[tag_idx[w[2]] for w in s] for s in sentence]\n",
    "y_challenge = pad_sequences(maxlen = max_len,sequences = y_challenge,padding =\n",
    "                        'post',value = tag_idx['O'])\n",
    "y_challenge = [to_categorical(i,num_classes = num_words_tag) for i in  y_challenge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_challenge[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_challenge, np.array(y_challenge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
